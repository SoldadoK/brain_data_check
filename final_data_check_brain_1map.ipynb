{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e108f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are less files in the map. Namely, 33 and their weight is 1.18 GB.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def check_files(directory_path):\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "    total_size_gb = sum(os.path.getsize(os.path.join(directory_path, f)) for f in files) / (1024 ** 3)\n",
    "\n",
    "    num_files = len(files)\n",
    "    expected_num_files = 34\n",
    "\n",
    "    if num_files == expected_num_files:\n",
    "        print(f\"There are the correct amount of files in the map, namely {expected_num_files} files, and their weight is {total_size_gb:.2f} GB.\")\n",
    "    else:\n",
    "        print(f\"There are {'less' if num_files < expected_num_files else 'more'} files in the map. Namely, {num_files} and their weight is {total_size_gb:.2f} GB.\")\n",
    "\n",
    "\n",
    "\n",
    "# Set the directory path\n",
    "directory_path = \"C:/Users/kovalsa/Documents/export_lab-visit/SU37009602\" # Replace this with the path to the directory you want to check\n",
    "check_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28cbdb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified scans:\n",
      "3D T1:\n",
      " - SU37009602_2_1.PAR (Weight: 51279 bytes) - OK\n",
      " - SU37009602_2_1.REC (Weight: 18350080 bytes) - OK\n",
      "fMRI highres:\n",
      " - SU37009602_3_1.PAR (Weight: 114452 bytes) - OK\n",
      " - SU37009602_3_1.nii (Weight: 8429920 bytes) - OK\n",
      " - SU37009602_3_1.REC (Weight: 8429568 bytes) - OK\n",
      "SDDT1:\n",
      " - SU37009602_8_1.PAR (Weight: 2639631 bytes) - OK\n",
      " - SU37009602_8_1.nii (Weight: 103885152 bytes) - OK\n",
      " - SU37009602_8_1.REC (Weight: 103884800 bytes) - OK\n",
      "SDDT2:\n",
      " - SU37009602_9_1.PAR (Weight: 2650031 bytes) - OK\n",
      " - SU37009602_9_1.nii (Weight: 104294752 bytes) - OK\n",
      " - SU37009602_9_1.REC (Weight: 104294400 bytes) - OK\n",
      "B0-map_RS:\n",
      " - SU37009602_13_1.PAR (Weight: 30504 bytes) - OK\n",
      " - SU37009602_13_1.nii (Weight: 9961824 bytes) - OK\n",
      " - SU37009602_13_1.REC (Weight: 9961472 bytes) - OK\n",
      "B0-map:\n",
      " - SU37009602_4_1.PAR (Weight: 30499 bytes) - OK\n",
      " - SU37009602_4_1.nii (Weight: 9961824 bytes) - OK\n",
      " - SU37009602_4_1.REC (Weight: 9961472 bytes) - OK\n",
      "Resting State:\n",
      " - SU37009602_14_1.PAR (Weight: 2575279 bytes) - OK\n",
      " - SU37009602_14_1.nii (Weight: 101350752 bytes) - OK\n",
      " - SU37009602_14_1.REC (Weight: 101350400 bytes) - OK\n",
      "SNAT1:\n",
      " - SU37009602_5_1.PAR (Weight: 1781631 bytes) - OK\n",
      " - SU37009602_5_1.nii (Weight: 70093152 bytes) - OK\n",
      " - SU37009602_5_1.REC (Weight: 70092800 bytes) - OK\n",
      "SNAT2:\n",
      " - SU37009602_6_1.PAR (Weight: 1709481 bytes) - OK\n",
      " - SU37009602_6_1.nii (Weight: 67251552 bytes) - OK\n",
      " - SU37009602_6_1.REC (Weight: 67251200 bytes) - OK\n",
      "SNAT3:\n",
      " - SU37009602_7_1.PAR (Weight: 1697456 bytes) - OK\n",
      " - SU37009602_7_1.nii (Weight: 66777952 bytes) - OK\n",
      " - SU37009602_7_1.REC (Weight: 66777600 bytes) - OK\n",
      "DTI A-P:\n",
      " - SU37009602_10_1.PAR (Weight: 756909 bytes) - OK\n",
      " - SU37009602_10_1.REC (Weight: 76185600 bytes) - OK\n",
      "DTI P-A:\n",
      " - SU37009602_11_1.PAR (Weight: 756909 bytes) - OK\n",
      " - SU37009602_11_1.REC (Weight: 76185600 bytes) - OK\n",
      "No abnormalities were found.\n",
      "\n",
      "Missing scans:\n",
      " - 3D T1\n",
      "   Formats: NII\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def identify_and_check_scans(directory_path):\n",
    "    # Tolerance in percentage\n",
    "    tolerance = 3.0\n",
    "\n",
    "    # Keywords to search in PAR files and expected file sizes in bytes (PAR, NII, REC)\n",
    "    scan_keywords_and_sizes = {\n",
    "        \"3D T1\": (\"PACS 3DT1\", [51278, 18350432, 18350080]),\n",
    "        \"fMRI highres\": (\"fMRI hires\", [114451, 8429920, 8429568]),\n",
    "        \"SDDT1\": (\"fMRI SDDT1 200\", [2641255, 103949152, 103948800]),\n",
    "        \"SDDT2\": (\"fMRI SDDT2 200\", [2652305, 104384352, 104384000]),\n",
    "        \"B0-map_RS\": (\"B0-map_RS\", [30503, 9961824, 9961472]),\n",
    "        \"B0-map\": (\"B0-map\", [30498, 9961824, 9961472]),\n",
    "        \"Resting State\": (\"rsfMRI 140\", [2575278, 101350752, 101350400]),\n",
    "        \"SNAT1\": (\"SNAT1 149\", [1781630, 70093152, 70092800]),\n",
    "        \"SNAT2\": (\"SNAT2 142\", [1709480, 67251552, 67251200]),\n",
    "        \"SNAT3\": (\"SNAT3 141\", [1697455, 66777952, 66777600]),\n",
    "        \"DTI A-P\": (\"jones30_P_NoCardiac\", [756906, None, 76185600]),\n",
    "        \"DTI P-A\": (\"jones30_A_NoCardiac\", [756906, None, 76185600])\n",
    "    }\n",
    "\n",
    "    identified_scans = {scan_type: [False, False, False] for scan_type in scan_keywords_and_sizes.keys()}\n",
    "    # Mark NII as True for DTI A-P and DTI P-A, since these scans don't have NII format\n",
    "    identified_scans[\"DTI A-P\"][1] = True\n",
    "    identified_scans[\"DTI P-A\"][1] = True\n",
    "    abnormal_files = []\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith(\".PAR\"):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                for scan_type, (keyword, expected_sizes) in scan_keywords_and_sizes.items():\n",
    "                    if keyword in content:\n",
    "                        identified_scans[scan_type][0] = True\n",
    "                        if os.path.exists(os.path.join(directory_path, file_name.replace(\".PAR\", \".nii\"))) and expected_sizes[1]:\n",
    "                            identified_scans[scan_type][1] = True\n",
    "                        if os.path.exists(os.path.join(directory_path, file_name.replace(\".PAR\", \".REC\"))):\n",
    "                            identified_scans[scan_type][2] = True\n",
    "\n",
    "                        nii_file_name = file_name.replace(\".PAR\", \".nii\")\n",
    "                        rec_file_name = file_name.replace(\".PAR\", \".REC\")\n",
    "                        \n",
    "                        files_with_sizes = [\n",
    "                            (file_name, os.path.getsize(os.path.join(directory_path, file_name))),\n",
    "                            (nii_file_name, os.path.getsize(os.path.join(directory_path, nii_file_name))) if identified_scans[scan_type][1] and expected_sizes[1] else (None, None),\n",
    "                            (rec_file_name, os.path.getsize(os.path.join(directory_path, rec_file_name))) if identified_scans[scan_type][2] else (None, None)\n",
    "                        ]\n",
    "\n",
    "                        identified_files = []\n",
    "                        for (file_name, file_size), expected_size in zip(files_with_sizes, expected_sizes):\n",
    "                            if expected_size is None or file_name is None:\n",
    "                                continue\n",
    "                            # Check the file size within tolerance\n",
    "                            lower_bound = expected_size * (1 - tolerance / 100)\n",
    "                            upper_bound = expected_size * (1 + tolerance / 100)\n",
    "                            if lower_bound <= file_size <= upper_bound:\n",
    "                                identified_files.append((file_name, file_size, \"OK\"))\n",
    "                            else:\n",
    "                                identified_files.append((file_name, file_size, \"Abnormal\"))\n",
    "                                abnormal_files.append((file_name, file_size, expected_size))\n",
    "                        identified_scans[scan_type].extend(identified_files)\n",
    "\n",
    "                        # Break after identifying a match, so that only the first match is used\n",
    "                        break\n",
    "\n",
    "    print(\"Identified scans:\")\n",
    "    for scan_type, scans in identified_scans.items():\n",
    "        scans = scans[3:]\n",
    "        print(scan_type + \":\")\n",
    "        for file_name, file_size, status in scans:\n",
    "            if file_name:\n",
    "                print(f\" - {file_name} (Weight: {file_size} bytes) - {status}\")\n",
    "\n",
    "    if abnormal_files:\n",
    "        print(\"\\nAbnormalities found:\")\n",
    "        for file_name, actual_size, expected_size in abnormal_files:\n",
    "            print(f\" - {file_name}\\n   Actual Weight: {actual_size} bytes\\n   Expected Weight: {expected_size} bytes\")\n",
    "    else:\n",
    "        print(\"No abnormalities were found.\")\n",
    "\n",
    "    # Check for missing scans and formats\n",
    "    print(\"\\nMissing scans:\")\n",
    "    missing_found = False\n",
    "    for scan_type, identified_formats in identified_scans.items():\n",
    "        missing_formats = []\n",
    "        if not identified_formats[0]: missing_formats.append(\"PAR\")\n",
    "        if not identified_formats[1] and scan_type not in [\"DTI A-P\", \"DTI P-A\"]: missing_formats.append(\"NII\")\n",
    "        if not identified_formats[2]: missing_formats.append(\"REC\")\n",
    "        if missing_formats:\n",
    "            missing_found = True\n",
    "            print(f\" - {scan_type}\")\n",
    "            print(f\"   Formats: {', '.join(missing_formats)}\")\n",
    "\n",
    "    if not missing_found:\n",
    "        print(\"No scans are missing.\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"C:/Users/kovalsa/Documents/export_lab-visit/SU37009602\" # Replace this with the path to the directory you want to check\n",
    "identify_and_check_scans(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f764d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
